{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "dataset = datasets.MNIST(\n",
    "    '../data', train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    ")\n",
    "\n",
    "x = dataset.data.float() / 255.\n",
    "y = dataset.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "class Block(nn.Moudel): \n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 output_size,\n",
    "                 use_batch_norm=True,\n",
    "                 dropout_p=.4):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        def get_regularizer(use_batch_norm, size):\n",
    "            return nn.BatchNorm1d(size) if use_batch_norm else nn.Dropout(dropout_p)\n",
    "        \n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(input_size, output_size),\n",
    "            nn.LeakyReLU(),\n",
    "            get_regularizer(use_batch_norm, output_size)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # |x| = (batch_size, input_size)\n",
    "        y = self.block(x)\n",
    "        # |y| = (batch_size, output_size)\n",
    "        \n",
    "        return y\n",
    "\n",
    "class MnistClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 output_size,\n",
    "                 hidden_sizes = [500,400,300,200,100],\n",
    "                 use_batch_norm = True,\n",
    "                 dropout_p = .3):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert len(hidden_sizes) > 0, \"you need to specify hidden layers\"\n",
    "        \n",
    "        last_hidden_size = input_size\n",
    "        blocks = []\n",
    "        \n",
    "        for hidden_size in hidden_sizes:\n",
    "            block += [Block(\n",
    "                last_hidden_size,\n",
    "                hidden_size,\n",
    "                use_batch_norm,\n",
    "                dropout_p\n",
    "            )]\n",
    "            last_hidden_size = hidden_size\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            *blocks,\n",
    "            nn.Linear(last_hidden_size, output_size),\n",
    "            nn.LogSoftmax(dim=-1)   \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # |x| = (batch_size, input_size)        \n",
    "        y = self.layers(x)\n",
    "        # |y| = (batch_size, output_size)\n",
    "        \n",
    "        return y      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt 설정\n",
    "train_ratio = 0.8\n",
    "train_cnt = int(x.size(0) * train_ratio)\n",
    "valid_cnt = x.size(0) - train_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle dataset to split into train/valid set\n",
    "x = x.view(x.size(0), -1)\n",
    "indices = torch.randperm(x.size(0))\n",
    "\n",
    "x = torch.index_select(\n",
    "    x, \n",
    "    dim=0,\n",
    "    index=indices\n",
    ").split([train_cnt, valid_cnt], dim = 0)\n",
    "\n",
    "\n",
    "y = torch.index_select(\n",
    "    y, \n",
    "    dim=0,\n",
    "    index=indices\n",
    ").split([train_cnt, valid_cnt], dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: torch.Size([48000, 784]) torch.Size([48000])\n",
      "Valid: torch.Size([12000, 784]) torch.Size([12000])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\", x[0].shape, y[0].shape)\n",
    "print(\"Valid:\", x[1].shape, y[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# model, optimizer, crit 설정 \n",
    "model = MnistClassifier(28**2, 10)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "crit = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class Trainer():\n",
    "    \n",
    "    def __init__(self, model, optimizer, crit):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer \n",
    "        self.crit = crit \n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "    def _train(self, x, y, config):\n",
    "        self.model.train()\n",
    "        \n",
    "        # shuffle before begin\n",
    "        indices = torch.randperm(x.size(0))\n",
    "        x = torch.index_select(x, dim=0, index=indices).split(config['batch_size'], dim=0)\n",
    "        y = torch.index_select(y, dim=0, index=indices).split(config['batch_size'], dim=0)\n",
    "        \n",
    "        total_loss = 0\n",
    "        \n",
    "        for i, (x_i, y_i) in enumerate(zip(x,y)):\n",
    "            y_hat_i = self.model(x_i)\n",
    "            loss_i = self.crit(y_hat_i, y_i.squeeze())\n",
    "            \n",
    "            # initialize the gradient of the model.\n",
    "            self.optimizer.zero_grad()\n",
    "            loss_i.backward()\n",
    "            \n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += float(loss_i)\n",
    "            \n",
    "        return total_loss / len(x)\n",
    "    \n",
    "    def _validate(self, x, y, config):\n",
    "        # Turn evaluation mode on. \n",
    "        self.model.eval()\n",
    "        \n",
    "        # Turn on the no_grad mode to make more efficiently.\n",
    "        with torch.no_grad():\n",
    "            # Suffle before begin.\n",
    "            indices = torch.randperm(x.size(0))\n",
    "            x = torch.index_select(x, dim=0, index=indices).split(config['batch_size'], dim=0)\n",
    "            y = torch.index_select(y, dim=0, index=indices).split(config['batch_size'], dim=0)\n",
    "            total_loss = 0\n",
    "            \n",
    "            for i, (x_i, y_i) in enumerate(zip(x,y)):\n",
    "                y_hat_i = self.model(x_i)\n",
    "                loss_i = self.crit(y_hat_i, y_i.squeeze())\n",
    "                \n",
    "                total_loss += float(loss_i)\n",
    "            \n",
    "            return total_loss / len(x)\n",
    "    \n",
    "    def train(self, train_data, valid_data, config):\n",
    "        lowest_loss = np.inf\n",
    "        best_model = None\n",
    "        \n",
    "        for epoch_index in range(config['n_epochs']):\n",
    "            train_loss = self._train(train_data[0], train_data[1], config)\n",
    "            valid_loss = self._validate(valid_data[0], valid_data[1], config)\n",
    "            \n",
    "            # You must use deep copy to take a snapshot of current best weights.\n",
    "            if valid_loss <= lowest_loss:\n",
    "                lowest_loss = valid_loss\n",
    "                best_model = deepcopy(self.model.state_dict())\n",
    "            \n",
    "            print(\"Epoch(%d/%d): train_loss=%.4e valid_loss=%.4e lowest_loss=%.4e\" % (\n",
    "                epoch_index + 1,\n",
    "                config['n_epochs'],\n",
    "                train_loss,\n",
    "                valid_loss,\n",
    "                lowest_loss\n",
    "            ))\n",
    "        # Restore to best model.\n",
    "        self.model.load_state_dict(best_model)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.. \n",
    "import argparse\n",
    "\n",
    "config = {\n",
    "    'batch_size' : 512,\n",
    "    'n_epochs' : 10,\n",
    "    'model_fn' : 'model.pth'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(1/10): train_loss=8.8278e-03 valid_loss=9.9897e-02 lowest_loss=9.9897e-02\n",
      "Epoch(2/10): train_loss=8.0993e-03 valid_loss=9.4777e-02 lowest_loss=9.4777e-02\n",
      "Epoch(3/10): train_loss=8.8160e-03 valid_loss=1.0403e-01 lowest_loss=9.4777e-02\n",
      "Epoch(4/10): train_loss=9.1608e-03 valid_loss=9.2695e-02 lowest_loss=9.2695e-02\n",
      "Epoch(5/10): train_loss=7.6500e-03 valid_loss=8.7332e-02 lowest_loss=8.7332e-02\n",
      "Epoch(6/10): train_loss=6.2263e-03 valid_loss=9.9235e-02 lowest_loss=8.7332e-02\n",
      "Epoch(7/10): train_loss=6.4061e-03 valid_loss=1.0266e-01 lowest_loss=8.7332e-02\n",
      "Epoch(8/10): train_loss=7.7165e-03 valid_loss=9.9298e-02 lowest_loss=8.7332e-02\n",
      "Epoch(9/10): train_loss=6.6252e-03 valid_loss=8.5051e-02 lowest_loss=8.5051e-02\n",
      "Epoch(10/10): train_loss=5.4342e-03 valid_loss=9.0510e-02 lowest_loss=8.5051e-02\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, optimizer, crit)\n",
    "\n",
    "trainer.train((x[0], y[0]), (x[1], y[1]), config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model weights.\n",
    "torch.save({\n",
    "    'model': trainer.model.state_dict(),\n",
    "    'config': config,\n",
    "}, config['model_fn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "def load_mnist(is_train=True, flatten=True):\n",
    "    from torchvision import datasets, transforms\n",
    "\n",
    "    dataset = datasets.MNIST(\n",
    "        '../data', train=is_train, download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ]),\n",
    "    )\n",
    "\n",
    "    x = dataset.data.float() / 255.\n",
    "    y = dataset.targets\n",
    "\n",
    "    if flatten:\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(fn):\n",
    "    d = torch.load(fn)\n",
    "    \n",
    "    return d['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = load_mnist(is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fn = \"./model.pth\"\n",
    "\n",
    "model = MnistClassifier(28**2, 10)\n",
    "model.load_state_dict(load(model_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, x, y, to_be_shown = True):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_hat = model(x)\n",
    "        \n",
    "        correct_cnt = (y.squeeze() == torch.argmax(y_hat, dim = -1)).sum()\n",
    "        total_cnt = float(x.size(0))\n",
    "        \n",
    "        accuracy = correct_cnt / total_cnt\n",
    "        print(\"Accuracy: %.4f\" % accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "test(model, x[:10], y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
